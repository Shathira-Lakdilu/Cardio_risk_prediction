{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KwBcRqvu2KrF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/cardio_dataset.csv').values\n",
        "data = dataset[:,0:7]   #load first 7 columns\n",
        "target = dataset[:,7]   #load 7th column"
      ],
      "metadata": {
        "id": "GpyK8ofl20eF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "target=np.reshape(target, (-1,1))  #only one column\n",
        "\n",
        "scaler_data = MinMaxScaler(feature_range=(0,1))\n",
        "scaler_target = MinMaxScaler()\n",
        "\n",
        "# first computes the minimum and maximum values of each feature in data (the fitting step), and then scales the data accordingly (the transformation step)\n",
        "data_scaled=scaler_data.fit_transform(data)\n",
        "target_scaled=scaler_target.fit_transform(target)\n",
        "\n",
        "print(scaler_data)"
      ],
      "metadata": {
        "id": "5bqGwjx0tSjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd16508-a2b6-47c2-e358-825cb7140a26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MinMaxScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data randomly to training datat and validation data. 20% for validation"
      ],
      "metadata": {
        "id": "217UhIb3H3gA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data, train_target, test_target = train_test_split(data_scaled, target_scaled, test_size=0.2)"
      ],
      "metadata": {
        "id": "E_TmOq4-tUie"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=7, activation='sigmoid',kernel_initializer='normal'))    #ist HL"
      ],
      "metadata": {
        "id": "t1lpCljBMrIZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The sigmoid activation function squashes the input values between\n",
        "0 and 1, which makes it particularly useful for binary classification problems or when you need output values in the range [0, 1].\n",
        "\n",
        "*   By randomly initializing weights from a normal distribution, you provide the network with a diverse set of starting points, which can help in exploring the parameter space more effectively during optimization.\n",
        "\n"
      ],
      "metadata": {
        "id": "-NgVwEf0P8XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dropout(0.5))"
      ],
      "metadata": {
        "id": "PapzusOEN05u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This adds a dropout layer with a dropout rate of 0.5, which randomly sets 50% of the input units to 0 at each update during training."
      ],
      "metadata": {
        "id": "tE66cFm0N7c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(64, activation='sigmoid'))    #2nd HL\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='sigmoid'))    #3rd HL\n",
        "model.add(Dense(1, activation='linear'))    #4th HL\n",
        "\n",
        "model.compile(optimizer='adam',loss='mse',metrics=['mse','mae'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "18BnSOAyN4nR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce27ff99-18f1-44d2-dced-789c3d59ae46"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               1024      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9941 (38.83 KB)\n",
            "Trainable params: 9941 (38.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import keras"
      ],
      "metadata": {
        "id": "7OG3o7yKVk7F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCallback(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self,epoch,logs=None):\n",
        "        global predicted_result\n",
        "        predicted_result=model.predict(test_data)\n",
        "        r2=r2_score(test_target,predicted_result)\n",
        "        print('epoch ',epoch,'- r2 score:',r2)"
      ],
      "metadata": {
        "id": "NxEIwYI7V-30"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/Models/model-{epoch:03d}.model',monitor='val_loss',save_best_only=True,mode='auto')"
      ],
      "metadata": {
        "id": "YnsCbLfYDdMo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_data,train_target,epochs=200,validation_data=(test_data,test_target),callbacks=[checkpoint,CustomCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6_kq_doFaVU",
        "outputId": "55ce0866-00aa-4e43-b0c7-3c01d4353386"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  0 - r2 score: 0.022619492432582322\n",
            "167/167 [==============================] - 6s 27ms/step - loss: 0.0373 - mse: 0.0373 - mae: 0.1453 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1162\n",
            "Epoch 2/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  1 - r2 score: 0.03151075931869918\n",
            "167/167 [==============================] - 3s 16ms/step - loss: 0.0247 - mse: 0.0247 - mae: 0.1200 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1168\n",
            "Epoch 3/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  2 - r2 score: 0.046699913462144305\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0237 - mse: 0.0237 - mae: 0.1178 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1147\n",
            "Epoch 4/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  3 - r2 score: 0.05839704618438013\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0227 - mse: 0.0227 - mae: 0.1151 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1076\n",
            "Epoch 5/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  4 - r2 score: 0.24907746236274386\n",
            "167/167 [==============================] - 2s 13ms/step - loss: 0.0211 - mse: 0.0211 - mae: 0.1097 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0997\n",
            "Epoch 6/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  5 - r2 score: 0.499723870305367\n",
            "167/167 [==============================] - 3s 20ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.0999 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0831\n",
            "Epoch 7/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  6 - r2 score: 0.6092928492048668\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0891 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0724\n",
            "Epoch 8/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  7 - r2 score: 0.6750985735039094\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0806 - val_loss: 0.0077 - val_mse: 0.0077 - val_mae: 0.0588\n",
            "Epoch 9/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  8 - r2 score: 0.713863068413095\n",
            "167/167 [==============================] - 2s 13ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0752 - val_loss: 0.0068 - val_mse: 0.0068 - val_mae: 0.0582\n",
            "Epoch 10/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  9 - r2 score: 0.7389264767008245\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0693 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0533\n",
            "Epoch 11/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  10 - r2 score: 0.761779627826444\n",
            "167/167 [==============================] - 3s 15ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0668 - val_loss: 0.0056 - val_mse: 0.0056 - val_mae: 0.0506\n",
            "Epoch 12/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  11 - r2 score: 0.7744832529252519\n",
            "167/167 [==============================] - 3s 18ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0633 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0518\n",
            "Epoch 13/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  12 - r2 score: 0.7926031809864719\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0614 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0438\n",
            "Epoch 14/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  13 - r2 score: 0.7755102974155106\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0609 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0448\n",
            "Epoch 15/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  14 - r2 score: 0.8005191494444202\n",
            "167/167 [==============================] - 3s 15ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0588 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0447\n",
            "Epoch 16/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  15 - r2 score: 0.8123069449181989\n",
            "167/167 [==============================] - 4s 25ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0571 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0430\n",
            "Epoch 17/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  16 - r2 score: 0.8288695643131752\n",
            "167/167 [==============================] - 3s 18ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0579 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0417\n",
            "Epoch 18/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  17 - r2 score: 0.8313030693830982\n",
            "167/167 [==============================] - 2s 10ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0556 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0396\n",
            "Epoch 19/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  18 - r2 score: 0.8246942762700976\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0555 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0392\n",
            "Epoch 20/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  19 - r2 score: 0.817329693193916\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0537 - val_loss: 0.0043 - val_mse: 0.0043 - val_mae: 0.0407\n",
            "Epoch 21/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  20 - r2 score: 0.8403339391667535\n",
            "167/167 [==============================] - 2s 9ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0542 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0393\n",
            "Epoch 22/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  21 - r2 score: 0.8247012880744886\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0528 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0396\n",
            "Epoch 23/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  22 - r2 score: 0.8386665789220509\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0525 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0381\n",
            "Epoch 24/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  23 - r2 score: 0.8397394968049735\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0520 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0383\n",
            "Epoch 25/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  24 - r2 score: 0.8423184135020396\n",
            "167/167 [==============================] - 2s 9ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0511 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0384\n",
            "Epoch 26/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  25 - r2 score: 0.8384382805652626\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0513 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0379\n",
            "Epoch 27/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  26 - r2 score: 0.8275408821984036\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0513 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0397\n",
            "Epoch 28/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  27 - r2 score: 0.8383099803926839\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0506 - val_loss: 0.0038 - val_mse: 0.0038 - val_mae: 0.0403\n",
            "Epoch 29/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  28 - r2 score: 0.8303266390023484\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0505 - val_loss: 0.0040 - val_mse: 0.0040 - val_mae: 0.0402\n",
            "Epoch 30/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  29 - r2 score: 0.8468871924852838\n",
            "167/167 [==============================] - 2s 13ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0495 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0400\n",
            "Epoch 31/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  30 - r2 score: 0.8472283925495734\n",
            "167/167 [==============================] - 3s 18ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0501 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0395\n",
            "Epoch 32/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  31 - r2 score: 0.8257813314138823\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0502 - val_loss: 0.0041 - val_mse: 0.0041 - val_mae: 0.0382\n",
            "Epoch 33/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  32 - r2 score: 0.8494902466019133\n",
            "167/167 [==============================] - 1s 9ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0496 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0401\n",
            "Epoch 34/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  33 - r2 score: 0.8465448036967377\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0492 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0415\n",
            "Epoch 35/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  34 - r2 score: 0.8421011101801757\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0490 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0367\n",
            "Epoch 36/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  35 - r2 score: 0.8511560170269926\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0494 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0394\n",
            "Epoch 37/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  36 - r2 score: 0.8454878466724244\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0480 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0378\n",
            "Epoch 38/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  37 - r2 score: 0.8526363892798159\n",
            "167/167 [==============================] - 2s 11ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0485 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0369\n",
            "Epoch 39/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  38 - r2 score: 0.8514104614688717\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0480 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0371\n",
            "Epoch 40/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  39 - r2 score: 0.8565322940957202\n",
            "167/167 [==============================] - 3s 18ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0474 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0359\n",
            "Epoch 41/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  40 - r2 score: 0.8487121393635726\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0482 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0400\n",
            "Epoch 42/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  41 - r2 score: 0.8524162256423362\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0470 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0394\n",
            "Epoch 43/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  42 - r2 score: 0.84533810298024\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0483 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0368\n",
            "Epoch 44/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  43 - r2 score: 0.8536194250747224\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0468 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0390\n",
            "Epoch 45/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  44 - r2 score: 0.8449934270430415\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0470 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0411\n",
            "Epoch 46/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  45 - r2 score: 0.8552743846711701\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0468 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0389\n",
            "Epoch 47/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  46 - r2 score: 0.8338829653122277\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0471 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0404\n",
            "Epoch 48/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  47 - r2 score: 0.8533388592546493\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0461 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0371\n",
            "Epoch 49/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  48 - r2 score: 0.8495843548509789\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0477 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0378\n",
            "Epoch 50/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  49 - r2 score: 0.8547242677751389\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0462 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0382\n",
            "Epoch 51/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  50 - r2 score: 0.8521022269004175\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0471 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0367\n",
            "Epoch 52/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  51 - r2 score: 0.8526853772713019\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0472 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0365\n",
            "Epoch 53/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  52 - r2 score: 0.8561155031964909\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0456 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0370\n",
            "Epoch 54/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  53 - r2 score: 0.8519526022432727\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0468 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0399\n",
            "Epoch 55/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  54 - r2 score: 0.857781596368752\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0458 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0368\n",
            "Epoch 56/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  55 - r2 score: 0.850719535702142\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0457 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0375\n",
            "Epoch 57/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  56 - r2 score: 0.8570579217594668\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0456 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0370\n",
            "Epoch 58/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  57 - r2 score: 0.846994474514866\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0455 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0359\n",
            "Epoch 59/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  58 - r2 score: 0.8556595725431335\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0459 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0376\n",
            "Epoch 60/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  59 - r2 score: 0.8499334318745225\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0462 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0391\n",
            "Epoch 61/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  60 - r2 score: 0.8541247850951034\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0451 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0369\n",
            "Epoch 62/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  61 - r2 score: 0.8592143350917884\n",
            "167/167 [==============================] - 3s 16ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0445 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0360\n",
            "Epoch 63/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  62 - r2 score: 0.8595965858664592\n",
            "167/167 [==============================] - 1s 9ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0455 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0356\n",
            "Epoch 64/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  63 - r2 score: 0.8598516504753548\n",
            "167/167 [==============================] - 2s 9ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0447 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0350\n",
            "Epoch 65/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  64 - r2 score: 0.8565999041547052\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0448 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0385\n",
            "Epoch 66/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  65 - r2 score: 0.8561867565040744\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0450 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0370\n",
            "Epoch 67/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  66 - r2 score: 0.8591171572621616\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0451 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0368\n",
            "Epoch 68/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  67 - r2 score: 0.8584169328750846\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0446 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0378\n",
            "Epoch 69/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  68 - r2 score: 0.848261004858382\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0444 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0430\n",
            "Epoch 70/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  69 - r2 score: 0.861112980754793\n",
            "167/167 [==============================] - 2s 13ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0451 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0356\n",
            "Epoch 71/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  70 - r2 score: 0.8533367334615376\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0455 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0404\n",
            "Epoch 72/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  71 - r2 score: 0.8564802345383609\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0447 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0391\n",
            "Epoch 73/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  72 - r2 score: 0.8602475623826457\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0451 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0368\n",
            "Epoch 74/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  73 - r2 score: 0.8464814524423857\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0438 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0432\n",
            "Epoch 75/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  74 - r2 score: 0.8606929286700019\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0446 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0357\n",
            "Epoch 76/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  75 - r2 score: 0.8612951818595245\n",
            "167/167 [==============================] - 2s 14ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0441 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0355\n",
            "Epoch 77/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  76 - r2 score: 0.8604810180853245\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0437 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0368\n",
            "Epoch 78/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  77 - r2 score: 0.8596957568034859\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0441 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0356\n",
            "Epoch 79/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  78 - r2 score: 0.8575034299877298\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0443 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0385\n",
            "Epoch 80/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  79 - r2 score: 0.8575566697204442\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0437 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0351\n",
            "Epoch 81/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  80 - r2 score: 0.8584627387493495\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0442 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0377\n",
            "Epoch 82/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  81 - r2 score: 0.8600163484011724\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0442 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0354\n",
            "Epoch 83/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  82 - r2 score: 0.8620437873909501\n",
            "167/167 [==============================] - 2s 12ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0437 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0351\n",
            "Epoch 84/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  83 - r2 score: 0.857160540558983\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0446 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0393\n",
            "Epoch 85/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  84 - r2 score: 0.8590055064878984\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0435 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0376\n",
            "Epoch 86/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  85 - r2 score: 0.8559671530388966\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0437 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0362\n",
            "Epoch 87/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  86 - r2 score: 0.8598313669567081\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0436 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0374\n",
            "Epoch 88/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  87 - r2 score: 0.8558853155026911\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0440 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0387\n",
            "Epoch 89/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  88 - r2 score: 0.8594048128428959\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0437 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0357\n",
            "Epoch 90/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  89 - r2 score: 0.8568214033111823\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0434 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0378\n",
            "Epoch 91/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  90 - r2 score: 0.8449392660013715\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0436 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0416\n",
            "Epoch 92/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  91 - r2 score: 0.8609779022722317\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0431 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0352\n",
            "Epoch 93/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  92 - r2 score: 0.8539751880154296\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0435 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0413\n",
            "Epoch 94/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  93 - r2 score: 0.847569034028653\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0432 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0404\n",
            "Epoch 95/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  94 - r2 score: 0.8520870048808519\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0439 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0410\n",
            "Epoch 96/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  95 - r2 score: 0.8611754117144542\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0428 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0351\n",
            "Epoch 97/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  96 - r2 score: 0.8608925035284669\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0428 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0345\n",
            "Epoch 98/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  97 - r2 score: 0.8598646699475654\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0432 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0370\n",
            "Epoch 99/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  98 - r2 score: 0.8623871458214913\n",
            "167/167 [==============================] - 2s 10ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0427 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0349\n",
            "Epoch 100/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  99 - r2 score: 0.8495268569484389\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0427 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0356\n",
            "Epoch 101/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  100 - r2 score: 0.8548139243592985\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0436 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0385\n",
            "Epoch 102/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  101 - r2 score: 0.8543545026245376\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0430 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0356\n",
            "Epoch 103/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  102 - r2 score: 0.8629885554684427\n",
            "167/167 [==============================] - 2s 13ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0428 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0348\n",
            "Epoch 104/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  103 - r2 score: 0.8473263381033165\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0428 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0440\n",
            "Epoch 105/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  104 - r2 score: 0.8576196110627243\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0429 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0392\n",
            "Epoch 106/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  105 - r2 score: 0.8579074668832831\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0433 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0383\n",
            "Epoch 107/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  106 - r2 score: 0.8620024206908051\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0430 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0362\n",
            "Epoch 108/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  107 - r2 score: 0.8496873127974491\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0424 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0424\n",
            "Epoch 109/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  108 - r2 score: 0.8600899662691501\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0443 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0378\n",
            "Epoch 110/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  109 - r2 score: 0.8612889189732951\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0428 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0373\n",
            "Epoch 111/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  110 - r2 score: 0.8570281575337511\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0426 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0365\n",
            "Epoch 112/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  111 - r2 score: 0.8593510063520464\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0429 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0345\n",
            "Epoch 113/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  112 - r2 score: 0.8601703777532812\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0426 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0369\n",
            "Epoch 114/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  113 - r2 score: 0.8529397852600415\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0433 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0368\n",
            "Epoch 115/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  114 - r2 score: 0.8613955572249451\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0429 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0369\n",
            "Epoch 116/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  115 - r2 score: 0.8548760848239815\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0426 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0372\n",
            "Epoch 117/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  116 - r2 score: 0.8582819520689288\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0422 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0384\n",
            "Epoch 118/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  117 - r2 score: 0.8595292306654856\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0430 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0370\n",
            "Epoch 119/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  118 - r2 score: 0.8480467966712224\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0417 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0414\n",
            "Epoch 120/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  119 - r2 score: 0.857418161092457\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0427 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0388\n",
            "Epoch 121/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  120 - r2 score: 0.8599986335476211\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0425 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0374\n",
            "Epoch 122/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  121 - r2 score: 0.8541382941656366\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0418 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0413\n",
            "Epoch 123/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  122 - r2 score: 0.8602912619286174\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0428 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0382\n",
            "Epoch 124/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  123 - r2 score: 0.8568048204998406\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0366\n",
            "Epoch 125/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  124 - r2 score: 0.8594146751706788\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0423 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0379\n",
            "Epoch 126/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  125 - r2 score: 0.8596858674820704\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0420 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0379\n",
            "Epoch 127/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  126 - r2 score: 0.8636230439351196\n",
            "167/167 [==============================] - 2s 9ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0353\n",
            "Epoch 128/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  127 - r2 score: 0.8532045157753849\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0432 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0417\n",
            "Epoch 129/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  128 - r2 score: 0.8632771288029744\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0426 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0351\n",
            "Epoch 130/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  129 - r2 score: 0.8601043387281848\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0426 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0371\n",
            "Epoch 131/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  130 - r2 score: 0.8621328449790392\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0422 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0369\n",
            "Epoch 132/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  131 - r2 score: 0.8576274142691905\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0378\n",
            "Epoch 133/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  132 - r2 score: 0.862218100192722\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0345\n",
            "Epoch 134/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  133 - r2 score: 0.8592012932265047\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0416 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0380\n",
            "Epoch 135/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  134 - r2 score: 0.8558738385202334\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0417 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0406\n",
            "Epoch 136/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  135 - r2 score: 0.8569225352448075\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0421 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0390\n",
            "Epoch 137/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  136 - r2 score: 0.862470344539577\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0418 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0346\n",
            "Epoch 138/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  137 - r2 score: 0.8625429691364399\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0414 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0356\n",
            "Epoch 139/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  138 - r2 score: 0.8570335062906318\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0418 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0355\n",
            "Epoch 140/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  139 - r2 score: 0.8634444413092266\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0420 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0359\n",
            "Epoch 141/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  140 - r2 score: 0.864129710488811\n",
            "167/167 [==============================] - 2s 15ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0422 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0348\n",
            "Epoch 142/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  141 - r2 score: 0.8596036955585267\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0412 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0346\n",
            "Epoch 143/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  142 - r2 score: 0.8620069153822415\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0422 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0354\n",
            "Epoch 144/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  143 - r2 score: 0.8539989023635415\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0416 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0392\n",
            "Epoch 145/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  144 - r2 score: 0.8627189344439518\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0365\n",
            "Epoch 146/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  145 - r2 score: 0.8626323883410789\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0422 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0343\n",
            "Epoch 147/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  146 - r2 score: 0.8542722850082689\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0423 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0406\n",
            "Epoch 148/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  147 - r2 score: 0.8619391870903494\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0355\n",
            "Epoch 149/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  148 - r2 score: 0.8631788561879612\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0412 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0357\n",
            "Epoch 150/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  149 - r2 score: 0.862544678822364\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0415 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0359\n",
            "Epoch 151/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  150 - r2 score: 0.8598910105450834\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0421 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0360\n",
            "Epoch 152/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  151 - r2 score: 0.8454905761816135\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0416 - val_loss: 0.0037 - val_mse: 0.0037 - val_mae: 0.0447\n",
            "Epoch 153/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  152 - r2 score: 0.8628102345826287\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0419 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0354\n",
            "Epoch 154/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  153 - r2 score: 0.8628961828847131\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0414 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0353\n",
            "Epoch 155/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  154 - r2 score: 0.857396005071517\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0415 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0365\n",
            "Epoch 156/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  155 - r2 score: 0.8565336297151426\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0418 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0400\n",
            "Epoch 157/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  156 - r2 score: 0.8612398014787138\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0414 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0363\n",
            "Epoch 158/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  157 - r2 score: 0.8609649936059405\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0413 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0353\n",
            "Epoch 159/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  158 - r2 score: 0.8621413822265923\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0409 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0367\n",
            "Epoch 160/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  159 - r2 score: 0.8581468280715994\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0414 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0376\n",
            "Epoch 161/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  160 - r2 score: 0.8621777372893809\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0372\n",
            "Epoch 162/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  161 - r2 score: 0.8571552510770544\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0408 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0396\n",
            "Epoch 163/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  162 - r2 score: 0.8634092181067139\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0412 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0354\n",
            "Epoch 164/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  163 - r2 score: 0.8639744271560748\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0416 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0351\n",
            "Epoch 165/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  164 - r2 score: 0.8619792169420684\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0410 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0372\n",
            "Epoch 166/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  165 - r2 score: 0.8632062784204365\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0354\n",
            "Epoch 167/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  166 - r2 score: 0.857496995876707\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0410 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0370\n",
            "Epoch 168/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  167 - r2 score: 0.8603853321775954\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0411 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0360\n",
            "Epoch 169/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  168 - r2 score: 0.8587966913299389\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0403 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0361\n",
            "Epoch 170/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  169 - r2 score: 0.8622580701407199\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0409 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0342\n",
            "Epoch 171/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  170 - r2 score: 0.8612145964896534\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0422 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0372\n",
            "Epoch 172/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  171 - r2 score: 0.8604240144467434\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0410 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0351\n",
            "Epoch 173/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  172 - r2 score: 0.8627016150478317\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0409 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0359\n",
            "Epoch 174/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  173 - r2 score: 0.8572810294493491\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0404 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0374\n",
            "Epoch 175/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  174 - r2 score: 0.8526381210902726\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0408 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0412\n",
            "Epoch 176/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  175 - r2 score: 0.861169382812239\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0377\n",
            "Epoch 177/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  176 - r2 score: 0.8570209026409954\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0406 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0373\n",
            "Epoch 178/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  177 - r2 score: 0.8617174690092582\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0413 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0373\n",
            "Epoch 179/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  178 - r2 score: 0.8521577372584554\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0421\n",
            "Epoch 180/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  179 - r2 score: 0.8633968055250913\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0412 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0351\n",
            "Epoch 181/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  180 - r2 score: 0.8637742823990131\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0404 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0357\n",
            "Epoch 182/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  181 - r2 score: 0.8633256455517566\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0398 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0359\n",
            "Epoch 183/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  182 - r2 score: 0.8491562597832678\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0422\n",
            "Epoch 184/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  183 - r2 score: 0.8564098258451439\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0389\n",
            "Epoch 185/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  184 - r2 score: 0.8619258597709121\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0374\n",
            "Epoch 186/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  185 - r2 score: 0.8604686871600556\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0399 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0377\n",
            "Epoch 187/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  186 - r2 score: 0.8606815483889338\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0410 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0355\n",
            "Epoch 188/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  187 - r2 score: 0.8627537545697859\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0401 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0366\n",
            "Epoch 189/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  188 - r2 score: 0.8564860476959427\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0347\n",
            "Epoch 190/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  189 - r2 score: 0.8600220977690993\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0410 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0343\n",
            "Epoch 191/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  190 - r2 score: 0.8629321580253075\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0402 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0362\n",
            "Epoch 192/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  191 - r2 score: 0.8517867290301243\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0035 - val_mse: 0.0035 - val_mae: 0.0421\n",
            "Epoch 193/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  192 - r2 score: 0.8610228983101049\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0408 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0375\n",
            "Epoch 194/200\n",
            "42/42 [==============================] - 0s 1ms/step\n",
            "epoch  193 - r2 score: 0.8571303428299023\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0402 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0387\n",
            "Epoch 195/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  194 - r2 score: 0.857576536220665\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0410 - val_loss: 0.0034 - val_mse: 0.0034 - val_mae: 0.0370\n",
            "Epoch 196/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  195 - r2 score: 0.8602448304563263\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0405 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0343\n",
            "Epoch 197/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  196 - r2 score: 0.8600354227943883\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0407 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0358\n",
            "Epoch 198/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  197 - r2 score: 0.8634031995854319\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0406 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0344\n",
            "Epoch 199/200\n",
            "42/42 [==============================] - 0s 2ms/step\n",
            "epoch  198 - r2 score: 0.8594129294643525\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0409 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0385\n",
            "Epoch 200/200\n",
            "42/42 [==============================] - 0s 3ms/step\n",
            "epoch  199 - r2 score: 0.8617759451798996\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0402 - val_loss: 0.0033 - val_mse: 0.0033 - val_mae: 0.0343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(model.history.history['loss'],label='Training Loss')\n",
        "plt.plot(model.history.history['val_loss'],label='Validation Loss')\n",
        "plt.xlabel('# epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "HeNvOZN9IGjv",
        "outputId": "ec2fdbc8-6b67-42f3-fc9c-b49802951a47"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('actual:',test_target[:10].T)\n",
        "print('predicted:',predicted_result[:10].T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYQmSCKJQt5",
        "outputId": "f2d8be24-d561-424f-f263-525da81e3276"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual: [[0.55685815 0.04923798 0.28370457 0.38100821 0.07502931 0.01758499\n",
            "  0.09495897 0.12895662 0.06447831 0.09026964]]\n",
            "predicted: [[0.44533202 0.0819784  0.34066036 0.3017626  0.14838034 0.03802386\n",
            "  0.06960778 0.14989968 0.09472828 0.09910433]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('actual inverse scaled:',scaler_target.inverse_transform(test_target[:10]).T)\n",
        "print('predicted inverse scaled:',scaler_target.inverse_transform(predicted_result[:10]).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbAfPOaxJUvj",
        "outputId": "85cad8ad-fa15-4f99-fbfa-1c21f8cf62fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual inverse scaled: [[47.6  4.3 24.3 32.6  6.5  1.6  8.2 11.1  5.6  7.8]]\n",
            "predicted inverse scaled: [[38.086823   7.092757  29.158329  25.840351  12.756843   3.3434355\n",
            "   6.037544  12.886442   8.180322   8.553599 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save all models"
      ],
      "metadata": {
        "id": "9T--jBBeJYkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(scaler_data,'scaler_data.sav')\n",
        "joblib.dump(scaler_target,'scaler_target.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ej7bLPiJaQy",
        "outputId": "71058dc8-a87e-4e12-a59d-b00a43afcd06"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler_target.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}